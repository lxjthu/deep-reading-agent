# 学术文献智能分析系统：开发进度与架构设计文档

**日期**: 2026-01-22
**版本**: V3.0 (Deep Reading Beta)

---

## 1. 项目愿景与核心理念

本项目旨在从传统的“信息提取工具”进化为**“Acemoglu 级”的深度科研助手**。我们不再满足于简单的摘要生成，而是追求对文献的深度解构、理论批判和实证复现。

**核心理念**：
1.  **双模驱动 (Hybrid AI Engine)**：
    *   **Kimi (Moonshot)**：利用其超长上下文（128k+）能力，担任“**文献阅读员**”和“**数据审计员**”，负责海量文本的吞吐与精准提取。（kimi价格相对DeepSeek较高，可先用DeepSeek处理，实在遇到过长的文本再调用kimi）
    *   **DeepSeek (R1-Reasoner)**：利用其深度推理（Thinking Mode）能力，担任“**理论家**”和“**计量专家**”，负责逻辑推演、机制分析和代码重构。
2.  **分治策略 (Divide and Conquer)**：
    *   拒绝“一锅端”式的粗糙处理，采用**串行拆解 (Sequential Extraction)** 模式，将长论文切分为引言、理论、数据、实证四个独立模块，逐个击破。

---

## 2. 当前系统架构

### 2.1 模块一：批量扫描与初筛 (Batch Scanner)
*   **入口**: `run_analyzer.ps1` -> `main.py`
*   **功能**:
    *   对 `pdf/` 目录下的文献进行批量扫描。
    *   **增量更新**: 自动识别新文件，跳过已处理文件。
    *   **多语言适配**: 无论英文还是中文论文，统一输出中文结构化信息。
    *   **产出**: `results.xlsx` (Excel 汇总表) + `reports/*.md` (基础研读报告)。

### 2.2 模块二：Stata 代码精修 (Code Refiner)
*   **入口**: `refine_stata.py` -> `stata_refiner.py`
*   **核心**: **DeepSeek-R1 (Acemoglu Mode)**
*   **功能**:
    *   扫描现有的 Markdown 报告。
    *   基于论文的方法论描述，重写 Stata 代码。
    *   **增强点**: 自动补充平行趋势检验、IV 过度识别检验、聚类标准误设置，并提供**全中文注释**和**实证避坑指南**。
    *   **断点续传**: 自动识别 `(Expert Refined)` 标记，避免重复消耗 Token。

### 2.3 模块三：深度研读 (Deep Reader) - *核心升级*
*   **入口**: `run_deep_read.py` -> `deep_analyzer.py`
*   **架构**: **串行提取 + 分布式分析 (Sequential Extraction & Distributed Analysis)**
*   **工作流**:
    1.  **Phase 1: 串行拆解 (Kimi)**
        *   *Round 1*: 提取 Introduction & Conclusion -> 交给 **Agent A (价值评估)**
        *   *Round 2*: 提取 Theory & Literature -> 交给 **Agent B (理论推演, DeepSeek)**
        *   *Round 3*: 提取 Data & Variables -> 交给 **Agent C (数据审计)**
        *   *Round 4*: 提取 Empirical Strategy -> 交给 **Agent D (计量分析, DeepSeek)**
    2.  **Phase 2: 综合推理 (DeepSeek)**
        *   基于上述四部分信息，绘制 **Mermaid 机制图谱**。
        *   撰写 **专家批判 (Critique)** 与 **未来选题建议**。
    3.  **Phase 3: 报告生成**
        *   生成包含 6 大板块、23 个维度的深度报告。

### 2.4 模块四：参考文献抽取与引用追踪 (References & Citation Tracing)
*   **入口**: `run_reference_extractor.ps1` -> `extract_references.py`；`run_citation_tracer.ps1` -> `citation_tracer.py`
*   **目标**:
    *   从 `*_segmented.md` 中定位并抽取文末参考文献列表，结构化写入 `references\*_references.xlsx`。
    *   基于参考文献表反向追踪正文引用位置，输出：
        *   `references\*_references_citation_trace.md`（按条目汇总的追踪日志）
        *   `references\*_references_with_citations.xlsx`（在原表上追加引用次数与上下文）
*   **关键设计点**:
    *   先用指纹（作者-年份 / 数字编号）做宽召回，再用 LLM 进行精确核验（减少同名作者误判）。
    *   输出的引用内容会围绕命中的原句扩展上下文，便于人工复核与快速理解。
    *   对中文论文：保留原文摘录，不额外生成“中文重述”，避免重复与歧义。

---

## 3. 今日工作总结 (Work Log)

### 已完成功能 (Done)
- [x] **基础架构搭建**: 完成 PDF 解析、Excel 导出、Markdown 生成全流程。
- [x] **增量更新机制**: 实现文件指纹识别，支持断点续传。
- [x] **中英双语支持**: Prompt 强制中文输出，解决英文文献阅读障碍。
- [x] **Stata 专家模式**: 成功接入 DeepSeek-R1，实现代码的深度重构与优化。
- [x] **深度研读架构重构**: 
    - 从“单次提取”重构为“**四次串行提取**”，解决了 Kimi 在处理复杂 Prompt 时容易丢失信息的 Bug。
    - 增加了 JSON 自动修复与 Raw Text 降级机制，保证程序健壮性。
- [x] **参考文献抽取与引用追踪**:
    - 支持从 segmented md 抽取参考文献表，并反向定位正文引用位置（含上下文摘录）。
    - 针对中文论文增加章节识别与标点/括号规范化，提升参考文献抽取与引用追踪的稳定性。

### 待测试/待优化 (To Do)
- [ ] **深度研读全流程测试**: 由于之前存在提取为空 (N/A) 的问题，刚刚完成了代码重构，需要等待下一次完整运行来验证效果。
- [ ] **Prompt 微调**: 根据 DeepSeek-R1 的思考反馈，进一步优化理论部分的 Prompt，使其批判更加犀利。
- [ ] **引用追踪精度与效率优化**: 在长文与高噪声 PDF 转换文本下，进一步减少“数字编号型引用”的误召回，降低不必要的 LLM 调用次数。

---

## 4. 下一步行动建议

1.   **知识库构建**: 考虑将提取出的“机制图谱”和“变量定义”存入向量数据库，构建一个属于您的学术知识库。
2.   **数据可视化**: 尝试将您的数据可视化，以便于您对数据进行可视化和探索。
3.   **引用追踪**: 尝试将您的引用追踪结果可视化，以便于您对引用关系进行可视化和探索。
---

*Generated by Trae AI Pair-Programmer*
